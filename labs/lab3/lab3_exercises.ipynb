{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 2023-2024 - UMONS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to regression and classification with Scikit-Learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4bV7mOa9W1Eu"
   },
   "source": [
    "This notebook is an introduction to the library [scikit-learn](https://scikit-learn.org/stable/), which provides numerous tools to easily perform machine learning tasks. \n",
    "\n",
    "In this lab, we will experiment with two of the most frequently encountered tasks in machine learning: \n",
    "  - **Regression**, for a continous outcome.\n",
    "  - **Classification**, for a discrete outcome.\n",
    "\n",
    "In order for you to first have a good feeling of the general pipeline of a machine learning task, we will perform:\n",
    "- Data splitting\n",
    "- Linear regression\n",
    "- One-hot encoding\n",
    "- $K$-nearest neighbors classification\n",
    "- Basic metrics for regression and classification\n",
    "- Confusion matrices\n",
    "\n",
    "We will start with an example of linear regression."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jBfdU_joaqrm"
   },
   "source": [
    "**Import the necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y90MCHqMa1j5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zx1zL4ura5ze"
   },
   "source": [
    "**Load the 'Pokemon.csv' dataset as a Pandas Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LuZ28dR_bsXi",
    "outputId": "953949cf-64d3-4c54-e218-15b2cba75dbe"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Pokemon.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change the Type 1 and Type 2 variables to categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "BRPoZ4YhbuLr",
    "outputId": "7f4450fa-b7c8-4ea6-f53b-c3cd360882cb"
   },
   "outputs": [],
   "source": [
    "print(df.dtypes)\n",
    "df = df.astype({'Type 1': 'category', 'Type 2': 'category', 'Generation': 'category', 'Legendary': 'category'})\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiupbAY9b-H2"
   },
   "source": [
    "**Create a variable `X` containing the predictor 'Attack' and a variable `y` containing the target variable 'HP'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Attack']]\n",
    "y = df['HP']\n",
    "sns.scatterplot(x='Attack', y='HP', data=df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the dataset into training and test sets following an 80%/20% partition.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "sbGfkAWmcbRN",
    "outputId": "6e304cdf-ea3e-4fbf-ca96-32cb9f845a34"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, test_size=0.2, shuffle=True, random_state=0\n",
    ")\n",
    "\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRsWArmDcj_Z"
   },
   "source": [
    "**Build a linear regression model and fit it to the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wofvXKaicjJB",
    "outputId": "abb5bc94-acbd-4a93-bea8-9ebcd078bc45"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HZtL8vxjc8yb"
   },
   "source": [
    "**Compute the mean squared error (MSE) on both the training and test sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EF08yODueNB9",
    "outputId": "c0f7b0e1-c431-4013-ea61-9d132b9155f4"
   },
   "outputs": [],
   "source": [
    "# Make predictions for both the training and the test sets.\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Compute the coefficient of determination and the mean square error on both sets.\n",
    "MSE_train = mean_squared_error(y_train, y_pred_train)\n",
    "MSE_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(f'MSE on training set: {MSE_train:.2f}')\n",
    "print(f'MSE on test set: {MSE_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAjY7FyheSwV"
   },
   "source": [
    "**Plot the regression line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "PIZ5v8MDem9w",
    "outputId": "3dd4d060-cf1e-4cbe-c603-daaee7439d44"
   },
   "outputs": [],
   "source": [
    "# Generate predictions out of the fitted model.\n",
    "x_plot = pd.DataFrame(np.linspace(0, 200, 100), columns=['Attack'])\n",
    "y_plot = model.predict(x_plot)\n",
    "\n",
    "# Plot the regression line.\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.scatterplot(x='Attack', y='HP', data=df)\n",
    "ax.plot(x_plot, y_plot, label='Regression line', color='red')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression task with a Linear Regression model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PLEEhDHje0Zm"
   },
   "source": [
    "**1) Your turn ! Create a variable `X` containing the predictors 'Attack' and 'Defense' and a variable `y` containing the target variable 'HP'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Split the dataset into a training and a test set. Follow an 80%/20% split partition, and make sure the dataset is shuffled.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YkbDiZxafwpD"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Fit a linear regression model to the training data.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) What is the expression of the fitted model ? You need to access the model's parameters using `.coef_` and `.intercept_` to answer this question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9Z0y3gxf2QS",
    "outputId": "69ffa580-2d41-47bc-cc5b-a0442f8fa6bd"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Using the fitted model, predict the values of the target variable 'HP' in the training and test sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) For both the training and test sets, evaluate the model's predictions using the Mean Squared Error (MSE). What do you observe ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCTnZI0vgrw4",
    "outputId": "9ff030de-b4e0-4425-d4f5-586d733e3ec9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Can you implement the mean squared error calculation on the test set and verify if the results match those obtained using scikit-learn?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) Consider the variable 'Generation' as additional predictor. We will treat it as a categorical variable and encode it using one-hot encoding.**\n",
    "\n",
    "We will not feed 'Generation' as is to the model. \n",
    "Instead, we'll use the `OneHotEncoder` class to preprocess it, which will create a new binary variable \n",
    "(also called 'dummy variable') for each of the $K$ categories of 'Generation'.\n",
    "\n",
    "Here, 'Generation' possesses $K=6$ categories, so the one-hot-encoding will create 6 binary variables. \n",
    "For each dummy variable, a '1' means that the observation belongs to that category, while a '0' \n",
    "means it does not. Note that, as each observation belongs to a single category, only 1 of the 6 \n",
    "dummy variables will take on the value '1', while the rest will be '0's."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can retrieve the categories of the variable 'Generation' using the method `Series.cat.categories`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Generation'].cat.categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.1) Create a variable `X` containing the predictors 'Attack', 'Defense', and 'Generation', and a variable `y` containing the target variable 'HP'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.2) Split the dataset intro training and test sets following a 80/20 partition.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We create a one-hot encoding for the variable 'Generation' using the `OneHotEncoder` class. Unknown categories are ignored using `handle_unknown='ignore'` (in the sense that all dummy columns are set to 0).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Function to remove the column to be encoded and add the encoded columns with correct feature names\n",
    "def encode_df(df, ohe):\n",
    "    encoding = ohe.transform(df[['Generation']])\n",
    "    return pd.concat([\n",
    "        df.drop(columns='Generation').reset_index(drop=True),\n",
    "        pd.DataFrame(encoding, columns=ohe.get_feature_names_out())\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.3) Fit the one-hot-encoder exclusively to the training set for the variable 'Generation'. Then, remove the column to be encoded and add the encoded columns with correct feature names. You can use the function `encode_df` defined above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any pre-processing step must be fitted to the training data only, as it would otherwise result in data leakage (i.e. the model having access to information contained in the test set during training). Once it is fitted to the training set, it can be then applied to the test set. \n",
    "\n",
    "This also includes the cases where you replace missing values with a column statistic (i.e. mean, media, max, min, etc...)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.4) Fit the Linear Regression model to the training set, and get the model's coefficients. How does the model write now ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.5) Predict the MSE on the training and test sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Task with a KNN classifier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9) Using the function `sns.histplot`, plot three histograms showing the distribution of the 'HP', 'Attack' and 'Defense' variables, using the `hue` parameter to distinguish if Pokemons are legendary. What do you observe?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lw9udYmhhX49"
   },
   "source": [
    "**10) Use the `KNeighborsClassifier` class of scikit-learn with 5 neighbors to predict whether a Pokemon is legendary or not, using the variables 'Attack', 'Defense', and 'HP' as features. To this end, apply the following steps:**\n",
    "- **Select the features and the target variable.**\n",
    "- **Split your dataset into a training and test set following a 80%/20% partition.**\n",
    "- **Fit the model to the training set, and predict the variable 'Legendary' on the training and test sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11) Compute the accuracy score of the model's predictions on the training and test sets using the function `accuracy_score`.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12) Can you implement the accuracy calculation on the test set and verify if the results match those obtained using scikit-learn?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13) Look at the distribution of the variable 'Legendary' in the test dataset using `sns.countplot`. What do you observe ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14) Get the confusion matrix of the predictions on the test set using the `confusion_matrix` function. What do you observe and how do you link your observations to the accuracy of the model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab3_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "bfe0e2b9b67a2fcef00021a1d2a516837bff30cf713e434b27f739f4afd30381"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
