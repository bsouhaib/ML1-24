{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 2023-2024 - UMONS\n",
    "\n",
    "# Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we'll experiment with multiclass classification. We'll consider several models, some of which will be covered later in the course.\n",
    "We'll be using the [Wine Quality](https://archive.ics.uci.edu/ml/datasets/wine+quality) dataset, which contains several attributes of white wines.\n",
    "Each observation is associated to a rating between 0 and 10 that will be the label of our classification task.\n",
    "\n",
    "The columns of the dataframe contain the following information :\n",
    "* fixed_acidity: amount of tartaric acid in g/dm^3\n",
    "* volatile_acidity: amount of acetic acid in g/dm^3 \n",
    "* citric_acid: amount of citric acid in g/dm^3\n",
    "* residual_sugar: amount of remaining sugar after fermentation stops in g/l\n",
    "* chlorides: amount of salt in wine \n",
    "* free_sulfur_dioxide: amount of free SO2\n",
    "* total_sulfur_dioxide: amount of free and bound forms of SO2\n",
    "* density: density of the wine\n",
    "* pH: PH level of the wine on a scale from 0 to 14\n",
    "* sulphates: amount of sulphates \n",
    "* alcohol: the percent of alcohol content\n",
    "* quality: quality of the wine (score between 0 and 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, accuracy_score,\n",
    "                             confusion_matrix, log_loss, classification_report)\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "import warnings\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We load the dataset 'wine.csv'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/wine.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Check the properties of this dataset (length, types, missing values).** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We predict the target 'quality' from all other features. We split the dataset into a training and test set following a 80/20 partition.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabel = 'quality'\n",
    "X = df.drop(ylabel, axis=1)\n",
    "y = df[ylabel]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, test_size=0.2, shuffle=True, random_state=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Look at the distribution of the variable 'quality' in the training set using `sns.countplot`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) For each continuous feature, plot a boxplot of this feature grouped by label values. Use the `sns.boxenplot` function of the seaborn library. Which features seem to be the most useful to predict the label 'quality'?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Plot the pairwise relationship of the most useful features using the function `sns.pairplot`. Plot a different color according to the value of the variable 'quality' using the `hue` parameter. What do you observe?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Define a simple pipeline where you first scale the data with `StandardScaler` to have zero mean and unit variance followed by a (linear) logistic regression. Then fit the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) One of the most useful tool to diagnose a classification model is the confusion matrix. Print it using `confusion_matrix` and `ConfusionMatrixDisplay`.**\n",
    "\n",
    "The size of the matrix is $n \\times n$, where $n$ is the number of classes. Each row represents the instances in an actual class, while each column represents the instances in a predicted class. A cell $i, j$ represents the number of instances of class $i$ that were predicted as class $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) From the confusion matrix, several performance metrics can be calculated for each class, as well as overall metrics. Using the function `classification_report`, generate a report of these different metrics. Use the argument `zero_division=0` to avoid warnings.**\n",
    "\n",
    "Here's what each of these terms represents:\n",
    "\n",
    "1. **Precision**: This is the ratio of correctly predicted positive observations to the total predicted positives. It is an indicator of the accuracy of the positive predictions. For class $i$, precision is calculated as:\n",
    "   $$\n",
    "   \\text{Precision}_i = \\frac{TP_i}{TP_i + FP_i}\n",
    "   $$\n",
    "   where $TP_i$ are the true positives and $FP_i$ are the false positives for class $i$.\n",
    "\n",
    "2. **Recall** (also known as Sensitivity or True Positive Rate): This is the ratio of correctly predicted positive observations to all observations in the actual class. It shows how well the model can find all the positive samples. For class $i$, recall is calculated as:\n",
    "   $$\n",
    "   \\text{Recall}_i = \\frac{TP_i}{TP_i + FN_i}\n",
    "   $$\n",
    "   where $FN_i$ are the false negatives for class $i$.\n",
    "\n",
    "3. **F1-Score**: This is the harmonic mean of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. It is particularly useful when the class distribution is uneven. F1-score is calculated as:\n",
    "   $$\n",
    "   \\text{F1-Score}_i = \\frac{2}{\\frac{1}{\\text{Precision}_i} + \\frac{1}{\\text{Recall}_i}} = 2 \\times \\frac{\\text{Precision}_i \\times \\text{Recall}_i}{\\text{Precision}_i + \\text{Recall}_i}\n",
    "   $$\n",
    "\n",
    "4. **Support**: This is the number of actual occurrences of the class in the specified dataset. It doesn’t reflect the model’s performance but is very useful for determining the significance of the classification metrics.\n",
    "\n",
    "These metrics can be averaged to obtain:\n",
    "- **Macro average**: This is the average of the precision, recall, and f1-score without taking class imbalance into account. It treats all classes equally, regardless of their support.\n",
    "- **Weighted average**: This averages the precision, recall, and f1-score, with weighting by support for each class. This means that the influence of each class's score on the overall average is proportional to the number of instances of that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The log loss\n",
    "\n",
    "The log loss for a multiclass classification model is calculated as follows:\n",
    "$$\n",
    "\\text{Log Loss} = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{k=1}^{K} y_{ik} \\log(p_{ik})\n",
    "$$\n",
    "where:\n",
    "- $n$ is the total number of observations.\n",
    "- $K$ is the number of classes.\n",
    "- $y_{ik}$ is a binary indicator (0 or 1) if class label $k$ is the correct classification for observation $i$.\n",
    "- $p_{ik}$ is the predicted probability that observation $i$ belongs to class $k$.\n",
    "\n",
    "Remember from the course that $\\argmin_{\\theta \\in \\Theta} \\mathbb{E}[-\\log p(Y; \\theta)] = \\argmin_{\\theta \\in \\Theta} \\text{KL}(p_\\theta, p)$.\n",
    "Since the distribution that minimizes the KL divergence is the true distribution, the expectation of the log loss will be minimized when the model always predicts the correct vector of probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) Predict probabilities using the `predict_proba` method of the logistic regression model. Then calculate the log loss using the `log_loss` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9) Based on `y_test_binarized`, compute the log loss manually and check that it corresponds to the previous log loss.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train)\n",
    "y_test_binarized = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10) We will now experiment with various models for classification. For each one of the following models, design a grid of hyperparameters based on the corresponding scikit-learn documentation:**\n",
    "- **[KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)**\n",
    "- **[Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)**\n",
    "- **[Linear Discriminant Analysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html)**\n",
    "- **[Quadratic Discriminant Analysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html)**\n",
    "- **[Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)**\n",
    "- **[Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)**\n",
    "- **[Gradient Boosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11) For each one of these models, select the hyperparameters that give the lowest log loss using the `RandomizedSearchCV` class. Don't forget to normalize the data if necessary. Compute the accuracy and log loss on the test dataset for the best hyperparameters.**\n",
    "\n",
    "**Print the best hyperparameters corresponding to each model and plot a confusion matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12) Create a pandas dataframe where each row corresponds to a model. The columns should correspond to the accuracy and log loss.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
